{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/gpreda/credit-card-fraud-detection-predictive-models\n",
    "\n",
    "https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd                 \n",
    "import numpy as np                  \n",
    "import matplotlib                   \n",
    "import matplotlib.pyplot as plt     \n",
    "import seaborn as sns               \n",
    "#%matplotlib inline                  \n",
    "import plotly.graph_objs as go      \n",
    "import plotly.figure_factory as ff  \n",
    "from plotly import tools            \n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical Details\n",
    "\n",
    "* import pandas as pd: Esta línea importa la biblioteca pandas y le da el alias pd. pandas es una biblioteca de Python que proporciona estructuras de datos y herramientas para el análisis de datos.\n",
    "\n",
    "* import numpy as np: Esta línea importa la biblioteca numpy y le da el alias np. numpy es una biblioteca de Python utilizada para realizar cálculos numéricos, especialmente en el contexto de matrices y arreglos multidimensionales.\n",
    "\n",
    "* import matplotlib: Esta línea importa el paquete matplotlib, que es una biblioteca de visualización de datos en Python.\n",
    "\n",
    "* import matplotlib.pyplot as plt: Esta línea importa el módulo pyplot de matplotlib y le da el alias plt. pyplot proporciona una interfaz para crear gráficos y visualizaciones en Python.\n",
    "\n",
    "* import seaborn as sns: Esta línea importa la biblioteca seaborn y le da el alias sns. seaborn es una biblioteca de visualización de datos en Python que proporciona una interfaz de alto nivel para crear gráficos estadísticos atractivos y informativos.\n",
    "\n",
    "* #%matplotlib inline: Esta línea es un comentario que se utiliza a menudo en entornos como Jupyter Notebook para mostrar gráficos directamente en el notebook. Sin embargo, está comentada, lo que significa que actualmente no tiene efecto en el código.\n",
    "\n",
    "* import plotly.graph_objs as go: Esta línea importa el módulo graph_objs del paquete plotly y le da el alias go. plotly es una biblioteca de visualización interactiva que permite crear gráficos interactivos y dinámicos.\n",
    "\n",
    "* import plotly.figure_factory as ff: Esta línea importa el módulo figure_factory del paquete plotly y le da el alias ff. figure_factory proporciona funciones para crear figuras complejas y personalizadas en Plotly.\n",
    "\n",
    "* from plotly import tools: Esta línea importa el módulo tools del paquete plotly. tools proporciona herramientas y utilidades adicionales para trabajar con gráficos en Plotly.\n",
    "\n",
    "* from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot: Esta línea importa varias funciones del módulo offline del paquete plotly. Estas funciones se utilizan para trabajar con Plotly en entornos fuera de línea, como Jupyter Notebook.\n",
    "\n",
    "* init_notebook_mode(connected=True): Esta línea inicializa el modo notebook de Plotly y lo conecta al entorno actual. Esto es necesario para que Plotly funcione correctamente en un entorno de cuaderno Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from datetime import datetime \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#from catboost import CatBoostClassifier\n",
    "from sklearn import svm\n",
    "#import lightgbm as lgb\n",
    "#from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical Details:\n",
    "\n",
    "* import gc: Esta línea importa el módulo gc, que es el módulo de recolección de basura de Python. Este módulo proporciona una interfaz para el recolector de basura de Python, que se encarga de liberar memoria ocupada por objetos que ya no son necesarios.\n",
    "\n",
    "* from datetime import datetime: Esta línea importa la clase datetime del módulo datetime. La clase datetime se utiliza para manipular fechas y horas en Python.\n",
    "\n",
    "* from sklearn.model_selection import train_test_split: Esta línea importa la función train_test_split del módulo model_selection en el paquete sklearn. Esta función se utiliza para dividir conjuntos de datos en conjuntos de entrenamiento y prueba para su posterior entrenamiento y evaluación de modelos de aprendizaje automático.\n",
    "\n",
    "\n",
    "* from sklearn.model_selection import KFold: Esta línea importa la clase KFold del módulo model_selection en el paquete sklearn. La clase KFold se utiliza para realizar validación cruzada mediante la división del conjunto de datos en k pliegues para evaluar el rendimiento del modelo.\n",
    "\n",
    "\n",
    "* from sklearn.metrics import roc_auc_score: Esta línea importa la función roc_auc_score del módulo metrics en el paquete sklearn. Esta función se utiliza para calcular el área bajo la curva ROC (ROC AUC) que es una métrica comúnmente utilizada para evaluar modelos de clasificación.\n",
    "\n",
    "* from sklearn.ensemble import RandomForestClassifier: Esta línea importa la clase RandomForestClassifier del módulo ensemble en el paquete sklearn. Esta clase implementa un algoritmo de aprendizaje automático conocido como Bosques Aleatorios, que se utiliza para tareas de clasificación.\n",
    "\n",
    "* from sklearn.ensemble import AdaBoostClassifier: Esta línea importa la clase AdaBoostClassifier del módulo ensemble en el paquete sklearn. Esta clase implementa un algoritmo de aprendizaje automático conocido como AdaBoost, que se utiliza para mejorar la precisión de los modelos de aprendizaje automático mediante el enfoque secuencial de clasificadores débiles.\n",
    "\n",
    "* import xgboost as xgb: Esta línea importa el paquete xgboost y le da un alias de xgb. XGBoost es una biblioteca de aprendizaje automático que proporciona una implementación eficiente de algoritmos de árboles de decisión para tareas de regresión y clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     PATH\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../input\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input'"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "\n",
    "RFC_METRIC = 'gini'  #metric used for RandomForrestClassifier\n",
    "NUM_ESTIMATORS = 100 #number of estimators used for RandomForrestClassifier\n",
    "NO_JOBS = 4 #number of parallel jobs used for RandomForrestClassifier\n",
    "\n",
    "\n",
    "#TRAIN/VALIDATION/TEST SPLIT\n",
    "#VALIDATION\n",
    "VALID_SIZE = 0.20 # simple validation using train_test_split\n",
    "TEST_SIZE = 0.20 # test size using_train_test_split\n",
    "\n",
    "#CROSS-VALIDATION\n",
    "NUMBER_KFOLDS = 5 #number of KFolds for cross-validation\n",
    "\n",
    "\n",
    "\n",
    "RANDOM_STATE = 2018\n",
    "\n",
    "MAX_ROUNDS = 1000 #lgb iterations\n",
    "EARLY_STOP = 50 #lgb early stop \n",
    "OPT_ROUNDS = 1000  #To be adjusted based on best validation rounds\n",
    "VERBOSE_EVAL = 50 #Print out metric result\n",
    "\n",
    "IS_LOCAL = False\n",
    "\n",
    "import os\n",
    "\n",
    "if(IS_LOCAL):\n",
    "    PATH=\"../input/credit-card-fraud-detection\"\n",
    "else:\n",
    "    PATH=\"../input\"\n",
    "print(os.listdir(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical Details:\n",
    "\n",
    "* pd.set_option('display.max_columns', 100): Esta línea establece una opción en pandas para mostrar un máximo de 100 columnas cuando se imprimen DataFrames en la salida. Esto significa que si tienes un DataFrame con más de 100 columnas, solo se mostrarán las primeras 100 y las demás se ocultarán.\n",
    "\n",
    "* RFC_METRIC = 'gini': La línea de código RFC_METRIC = 'gini' está definiendo una variable llamada  RFC_METRIC y le está asignando el valor 'gini'. Esta variable se utiliza para especificar la métrica que se utilizará para evaluar el rendimiento de un clasificador de Bosques Aleatorios (Random Forest Classifier o RFC).\n",
    "\n",
    "    Ahora, hablemos un poco más sobre qué es la métrica Gini y cómo se relaciona con los Bosques Aleatorios:\n",
    "\n",
    "    * Gini: La métrica Gini, también conocida como coeficiente de Gini, es una medida de impureza utilizada en la construcción de árboles de decisión. En el contexto de los Bosques Aleatorios, la métrica Gini se utiliza para evaluar la calidad de una división en un árbol de decisión durante el proceso de construcción del bosque.\n",
    "\n",
    "    * Clasificador de Bosques Aleatorios: Un Bosque Aleatorio es un tipo de algoritmo de aprendizaje automático que utiliza múltiples árboles de decisión para realizar la clasificación de datos. Cada árbol de decisión en el bosque se entrena de forma independiente utilizando una muestra aleatoria del conjunto de datos y produce una predicción. Luego, las predicciones de todos los árboles en el bosque se combinan para obtener una predicción final.\n",
    "    \n",
    "    Cuando se utiliza la métrica Gini en un Bosque Aleatorio, se evalúa la pureza de cada división en cada árbol de decisión. La división que minimiza la impureza (o maximiza la pureza) se elige como la mejor división en cada nodo del árbol. Esto ayuda a mejorar la precisión del modelo y a reducir el sobreajuste.\n",
    "\n",
    "    En resumen, al definir RFC_METRIC = 'gini', estamos especificando que la métrica Gini se utilizará para evaluar el rendimiento del clasificador de Bosques Aleatorios en el código más adelante. Esto nos permite ajustar y evaluar el modelo de acuerdo con esta métrica específica.\n",
    "\n",
    "\n",
    "\n",
    "* NUM_ESTIMATORS = 100: Se define una variable llamada NUM_ESTIMATORS y se le asigna el valor 100. Esta variable se utiliza para especificar el número de estimadores (es decir, árboles de decisión) que se utilizarán en un clasificador de bosque aleatorio.\n",
    "\n",
    "    En el contexto de un clasificador de Bosque Aleatorio (Random Forest Classifier), los \"estimadores\" se refieren a los árboles de decisión individuales que componen el bosque. Cada árbol de decisión en el bosque se entrena de forma independiente y luego contribuye a la predicción final del modelo.\n",
    "\n",
    "    La línea NUM_ESTIMATORS = 100 está definiendo una variable llamada NUM_ESTIMATORS y le está asignando el valor 100. Esta variable se utiliza para especificar el número de árboles de decisión que se utilizarán en el clasificador de Bosque Aleatorio. En este caso, se ha decidido utilizar 100 árboles de decisión en el bosque.\n",
    "\n",
    "    Aquí hay algunos puntos adicionales para entender mejor esta configuración:\n",
    "\n",
    "    * Impacto en el rendimiento del modelo: El número de estimadores (o árboles) en un Bosque Aleatorio puede afectar significativamente el rendimiento del modelo. En general, un mayor número de árboles tiende a mejorar la precisión del modelo, pero también puede aumentar el tiempo de entrenamiento y la complejidad del modelo.\n",
    "  \n",
    "\n",
    "    * Equilibrio entre rendimiento y eficiencia: La elección del número de estimadores es un compromiso entre la precisión del modelo y la eficiencia computacional. Es importante encontrar un equilibrio que proporcione un buen rendimiento sin sacrificar demasiado tiempo de entrenamiento o recursos computacionales.\n",
    "  \n",
    "    * Técnica de ajuste de hiperparámetros: El número de estimadores es uno de los hiperparámetros que se pueden ajustar durante el entrenamiento del Bosque Aleatorio utilizando técnicas como la validación cruzada. A menudo, se realizan experimentos con diferentes valores de NUM_ESTIMATORS para encontrar el valor óptimo que maximice la precisión del modelo.\n",
    "\n",
    "\n",
    "* NO_JOBS = 4: Se define una variable llamada NO_JOBS y se le asigna el valor 4. Esta variable se utiliza para especificar el número de trabajos paralelos que se ejecutarán al entrenar el clasificador de bosque aleatorio. Esto puede acelerar el proceso de entrenamiento utilizando múltiples núcleos de CPU.\n",
    "\n",
    "\n",
    "* VALID_SIZE = 0.20 y TEST_SIZE = 0.20: Estas líneas definen las proporciones del conjunto de datos que se utilizarán para la validación y prueba cuando se divida el conjunto de datos para su entrenamiento y evaluación.\n",
    "\n",
    "    Estas variables definen las proporciones del conjunto de datos que se utilizarán para la validación y prueba cuando se divida el conjunto de datos para su entrenamiento y evaluación.\n",
    "\n",
    "    * VALID_SIZE = 0.20: Esto significa que el 20% del conjunto de datos total se utilizará para la validación. Cuando entrenamos un modelo de aprendizaje automático, es importante evaluar su rendimiento en un conjunto de datos separado que el modelo no ha visto durante el entrenamiento. Esta porción del conjunto de datos se utiliza para la validación, donde podemos ajustar los hiperparámetros del modelo y evaluar su rendimiento antes de aplicarlo a datos completamente nuevos.\n",
    "\n",
    "    * TEST_SIZE = 0.20: Esto significa que también el 20% del conjunto de datos total se utilizará para la prueba. Una vez que hemos entrenado y validado nuestro modelo, necesitamos evaluar su rendimiento final en un conjunto de datos independiente para obtener una estimación más precisa de cómo se comportará el modelo en la práctica. Esta porción del conjunto de datos se utiliza para la prueba, donde se realiza la evaluación final del rendimiento del modelo.\n",
    "    \n",
    "    Al especificar estas proporciones (en este caso, el 20% para la validación y el 20% para la prueba), estamos dividiendo correctamente nuestro conjunto de datos en tres partes distintas: entrenamiento, validación y prueba. Esto nos permite desarrollar y evaluar nuestro modelo de manera efectiva, asegurando que sea capaz de generalizar bien a datos nuevos y no vistos anteriormente.\n",
    "\n",
    "\n",
    "\n",
    "* NUMBER_KFOLDS = 5: Aquí se define el número de pliegues que se utilizarán en la validación cruzada mediante KFold. Esto determina cómo se dividirá el conjunto de datos en diferentes subconjuntos para la validación cruzada.\n",
    "\n",
    "    En el contexto de la validación cruzada mediante K-Fold (KFold Cross-Validation), NUMBER_KFOLDS especifica el número de pliegues que se utilizarán para dividir el conjunto de datos durante el proceso de validación cruzada.\n",
    "\n",
    "    La validación cruzada es una técnica utilizada para evaluar el rendimiento de un modelo de aprendizaje automático. En lugar de dividir el conjunto de datos en un conjunto de entrenamiento y otro de prueba, la validación cruzada divide el conjunto de datos en varios subconjuntos o \"pliegues\". Luego, el modelo se entrena y evalúa repetidamente utilizando diferentes combinaciones de estos pliegues.\n",
    "\n",
    "    ¿Por qué se utiliza K-Fold Cross-Validation?\n",
    "\n",
    "    La validación cruzada mediante K-Fold es útil porque proporciona una estimación más confiable del rendimiento del modelo al promediar los resultados obtenidos en múltiples divisiones del conjunto de datos. Esto ayuda a reducir el sesgo y la variabilidad asociados con una sola división de datos en entrenamiento y prueba.\n",
    "\n",
    "    Ejemplo:\n",
    "\n",
    "    Imagina que tienes un conjunto de datos de 1000 ejemplos y has decidido utilizar K-Fold Cross-Validation con NUMBER_KFOLDS = 5. Esto significa que el conjunto de datos se dividirá en 5 pliegues o partes iguales, cada una con 200 ejemplos.\n",
    "\n",
    "    Durante el proceso de validación cruzada, el modelo se entrenará y evaluará cinco veces, utilizando un pliegue diferente como conjunto de prueba en cada iteración y el resto de los pliegues como conjunto de entrenamiento. Al final, se promedian los resultados de las cinco iteraciones para obtener una medida general del rendimiento del modelo.\n",
    "\n",
    "    En resumen, al definir NUMBER_KFOLDS = 5, estamos especificando el número de pliegues que se utilizarán en la validación cruzada, lo que nos permite evaluar el rendimiento del modelo de manera más robusta y confiable.\n",
    "\n",
    "\n",
    "* RANDOM_STATE = 2018: Se establece una semilla aleatoria para garantizar la reproducibilidad de los resultados. Al fijar una semilla aleatoria, los resultados serán consistentes cada vez que se ejecute el código. La elección de \"2018\" como semilla aleatoria puede haber sido simplemente una elección arbitraria del autor del código o del proyecto. A menudo, los practicantes de aprendizaje automático eligen números que les resultan memorables o fáciles de recordar, como años, fechas especiales o secuencias numéricas significativas para ellos.\n",
    "\n",
    "    En el aprendizaje automático, especialmente cuando se utilizan algoritmos que involucran aleatoriedad (como la división de datos aleatoria o la inicialización de pesos aleatorios), puede ser útil fijar una semilla aleatoria para garantizar la reproducibilidad de los resultados.\n",
    "\n",
    "    Al establecer RANDOM_STATE = 2018, estamos fijando una semilla aleatoria específica para que los resultados sean consistentes cada vez que se ejecute el código. Esto significa que, aunque haya elementos de aleatoriedad en el proceso (como la selección aleatoria de datos de entrenamiento y prueba), los resultados obtenidos serán los mismos cada vez que se ejecute el código con la misma semilla aleatoria.\n",
    "\n",
    "    Beneficios de establecer una semilla aleatoria:\n",
    "\n",
    "  1. Reproducibilidad: Al fijar una semilla aleatoria, podemos reproducir los mismos resultados cada vez que se ejecute el código. Esto es útil para la depuración, la verificación y la comparación de resultados entre diferentes ejecuciones del código.\n",
    "   \n",
    "  2. Consistencia: Los resultados consistentes facilitan la comparación de diferentes modelos, configuraciones y experimentos. Esto ayuda a garantizar que los resultados observados sean atribuibles a los cambios en el modelo o la configuración, en lugar de la variabilidad aleatoria.\n",
    "   \n",
    "  3. Control: Fijar una semilla aleatoria proporciona un mayor control sobre el proceso de entrenamiento del modelo. Podemos ajustar y experimentar con diferentes aspectos del modelo con la confianza de que los resultados seguirán siendo consistentes.\n",
    "\n",
    "\n",
    "* MAX_ROUNDS = 1000, EARLY_STOP = 50 y OPT_ROUNDS = 1000: Estas variables se utilizan para configurar los parámetros de entrenamiento de un modelo de Gradient Boosting (por ejemplo, LightGBM). Determinan el número máximo de iteraciones, el criterio de parada temprana y el número óptimo de iteraciones, respectivamente.\n",
    "\n",
    "\n",
    "\n",
    "* VERBOSE_EVAL = 50: Esta variable especifica la frecuencia con la que se imprimirán los resultados de las métricas durante el proceso de evaluación del modelo.\n",
    "\n",
    "* IS_LOCAL = False: Se define una bandera booleana que indica si el código se está ejecutando en un entorno local o remoto. Esto determina el directorio de trabajo que se utilizará para cargar los datos.\n",
    "\n",
    "* import os: Se importa el módulo os, que proporciona funciones para interactuar con el sistema operativo subyacente, como leer o escribir archivos, crear directorios, entre otros.\n",
    "El bloque condicional if(IS_LOCAL): ... else: ... se utiliza para establecer el directorio de trabajo dependiendo del valor de IS_LOCAL. Si IS_LOCAL es True, se establece el directorio de trabajo en \"../input/credit-card-fraud-detection\"; de lo contrario, se establece en \"../input\".\n",
    "print(os.listdir(PATH)): Aquí se imprime una lista de todos los archivos y carpetas dentro del directorio especificado por PATH. Esto ayuda a verificar qué archivos están disponibles para cargar y utilizar en el proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Concepts\n",
    "\n",
    "### Árboles de Decisión:\n",
    "\n",
    "Imagina que estás jugando a un juego de adivinanzas donde tienes que adivinar un objeto. El juego consiste en hacer una serie de preguntas sí/no para reducir las opciones y finalmente llegar a la respuesta correcta.\n",
    "\n",
    "Un árbol de decisión funciona de manera similar. Comienza con una pregunta en la parte superior y, en función de la respuesta, se mueve hacia abajo en el árbol, haciendo más preguntas hasta llegar a una predicción.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "Imagina que estás tratando de decidir si debes salir de casa o quedarte adentro. Aquí hay un árbol de decisión simple que podrías seguir:\n",
    "\n",
    "¿Está lloviendo?\n",
    "Sí: Quédate adentro.\n",
    "No: Continúa con la siguiente pregunta.\n",
    "¿Hace sol?\n",
    "Sí: Sal fuera.\n",
    "No: Quédate adentro.\n",
    "Este es un ejemplo básico de un árbol de decisión. Comienza con una pregunta sobre el estado del tiempo y, dependiendo de la respuesta, toma una decisión sobre salir o quedarse adentro.\n",
    "\n",
    "Aplicación en la vida real:\n",
    "\n",
    "Imagina que eres un gerente de recursos humanos y estás tratando de decidir si debes contratar a un candidato para un puesto en tu empresa. Aquí hay un árbol de decisión simplificado que podrías seguir:\n",
    "\n",
    "¿El candidato tiene experiencia laboral relevante?\n",
    "Sí: Continúa con la siguiente pregunta.\n",
    "No: No contrates al candidato.\n",
    "¿El candidato tiene habilidades de comunicación fuertes?\n",
    "Sí: Contrata al candidato.\n",
    "No: No contrates al candidato.\n",
    "En este ejemplo, el árbol de decisiones te guía a través de una serie de preguntas relevantes para determinar si debes contratar al candidato. Cada pregunta te ayuda a tomar una decisión informada basada en ciertas características del candidato.\n",
    "\n",
    "### K-Fold\n",
    "\n",
    "La validación cruzada mediante K-Fold puede ser muy útil al trabajar con árboles de decisiones y otros modelos de aprendizaje automático. Aquí hay algunas formas en que K-Fold puede ayudar a mejorar la efectividad de los árboles de decisiones:\n",
    "\n",
    "1. Evaluación del rendimiento del modelo: La validación cruzada K-Fold proporciona una evaluación más robusta y confiable del rendimiento del modelo. Al realizar múltiples divisiones del conjunto de datos y promediar los resultados, obtenemos una estimación más precisa de cómo se comportará el modelo en la práctica.\n",
    "\n",
    "2. Identificación de sobreajuste: K-Fold puede ayudar a identificar si el árbol de decisiones está sobreajustado a los datos de entrenamiento. Si el modelo muestra un rendimiento significativamente peor en los conjuntos de prueba en comparación con los conjuntos de entrenamiento, puede ser una señal de que el modelo está sobreajustado y necesita ser ajustado.\n",
    "\n",
    "3. Ajuste de hiperparámetros: K-Fold es útil para ajustar los hiperparámetros del árbol de decisiones. Podemos realizar múltiples iteraciones de validación cruzada con diferentes valores de hiperparámetros y elegir aquellos que produzcan el mejor rendimiento promedio en los conjuntos de prueba.\n",
    "\n",
    "4. Mejora de la generalización: Al evaluar el modelo en múltiples divisiones del conjunto de datos, K-Fold ayuda a garantizar que el modelo generalice bien a datos nuevos y no vistos anteriormente. Esto es crucial para asegurar que el modelo sea útil en situaciones del mundo real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
